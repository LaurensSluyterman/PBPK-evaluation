{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs4fCdRNnr3j1oBO561Gv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaurensSluyterman/PBPK-evaluation/blob/main/PBPK_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This colab contains all the necessary code to calculate a confidence interval for a geometric mean ratio as is advocated in our paper:\n",
        "\n",
        "*van Borselen, M.D., Sluijterman, L.A.Ã†., Greupink, R. et al. Towards More Robust Evaluation of the Predictive Performance of Physiologically Based Pharmacokinetic Models: Using Confidence Intervals to Support Use of Model-Informed Dosing in Clinical Care. Clin Pharmacokinet (2024). https://doi.org/10.1007/s40262-023-01326-3*\n"
      ],
      "metadata": {
        "id": "O4CFt2EiA6C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title The code that is used ot create the intervals (run this first)\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "def CI_I_LD(observations, predictions, alpha=0.1):\n",
        "    \"\"\"This function calculates a confidence interval using the individual\n",
        "    predictions.\n",
        "\n",
        "    The interval is calculated on logscale using two paired t-tests and then\n",
        "    transformed back to the original scale. For more details on the reasoning\n",
        "    behind the interval, please see our paper: ....\n",
        "\n",
        "    Arguments:\n",
        "      observations: An array containing the individual observations\n",
        "      predictions: An array containing the individual predictions\n",
        "      alpha: A float that determines the significance of the confidence interval.\n",
        "        The significance is (1-alpha/2)*100%.\n",
        "\n",
        "    Return:\n",
        "      None\n",
        "    \"\"\"\n",
        "    # Some preliminary checks\n",
        "    if len(observations) != len(predictions):\n",
        "      print('different number of predictions and observations')\n",
        "      return\n",
        "    if alpha > 1:\n",
        "      print('alpha cannot be larger than 1. For a 90% confidence interval, use alpha=0.1')\n",
        "    # Convert to logscale\n",
        "    error_values = np.log(predictions) - np.log(observations)\n",
        "\n",
        "    # Calcualte a CI on logscale for the mean of the error\n",
        "    N = len(error_values)\n",
        "    var = np.var(error_values)\n",
        "    average = np.mean(error_values)\n",
        "    t = scipy.stats.t(N-1).ppf(1-alpha/2)\n",
        "    loglowerbound = average - t * np.sqrt(var / N)\n",
        "    logupperbound = average + t * np.sqrt(var / N)\n",
        "\n",
        "    # Convert the CI back to the original scale\n",
        "    CI = [np.exp(loglowerbound), np.exp(logupperbound)]\n",
        "\n",
        "    # Print the result\n",
        "    print(f'GM-ratio: {np.exp(np.mean(error_values))}')\n",
        "    print(f'{100*(1-alpha)}% confidence interval: {CI}')\n",
        "\n",
        "\n",
        "def CI_G_LD(GM_observed, GM_predicted, GCV_observed, GCV_predicted,\n",
        "            N_observed, N_predicted, alpha=0.1):\n",
        "    \"\"\"\n",
        "    Calculate CI using the GLM approach and considering variance of predictions.\n",
        "\n",
        "    This function calculates a CI of the difference in means on logscale and\n",
        "    then transform this back to the original scale. A 2-sided unpaired\n",
        "    t-test assuming unequal variances is used.\n",
        "\n",
        "    Arguments:\n",
        "        GM_observed: Observed geometric mean\n",
        "        GM_predicted: Predicted geometric mean\n",
        "        GCV_observed: Observed geometric coefficient of variation\n",
        "        GCV_predicted: Predicted geometric coefficient of variation\n",
        "        N_observed: Number of observed subjects\n",
        "        N_predicted: Number of predicted subjects\n",
        "        alpha: Confidence level. The default value of 0.1 corresponds to 90% CI.\n",
        "\n",
        "    Returns:\n",
        "        CI: The (1-alpha)*100% confidence interval.\n",
        "    \"\"\"\n",
        "    if type(N_observed) != int:\n",
        "      raise ValueError('N_observed must be an integer, do not use dots.')\n",
        "    if type(N_predicted) != int:\n",
        "      raise ValueError('N_predicted must be an integer, do not use dots.')\n",
        "    average_observed = np.log(GM_observed)\n",
        "    average_predicted = np.log(GM_predicted)\n",
        "    var_observed = np.log(GCV_observed**2 + 1)\n",
        "    var_predicted = np.log(GCV_predicted**2 + 1)\n",
        "    var_total = var_observed / N_observed + var_predicted / N_predicted\n",
        "    df = (var_total)**2 \\\n",
        "     / ((var_observed / N_observed)**2 / (N_observed - 1) + (var_predicted / N_predicted)**2 / (N_predicted - 1))\n",
        "    t = scipy.stats.t(df).ppf(1-alpha/2)\n",
        "    loglowerbound = average_predicted - average_observed - t * np.sqrt(var_total)\n",
        "    logupperbound = average_predicted - average_observed + t * np.sqrt(var_total)\n",
        "    CI = [np.exp(loglowerbound), np.exp(logupperbound)]\n",
        "    print(f'GM-ratio: {GM_predicted / GM_observed}')\n",
        "    print(f'{100*(1-alpha)}% confidence interval: {CI}')\n"
      ],
      "metadata": {
        "id": "EPDAGOEH9VBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation of the code is give in the code block above. The above code block must be run first"
      ],
      "metadata": {
        "id": "tOubSX306qqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I-LD Approach: When individual level data is available\n",
        "\n",
        "The cell below illustrates how a confidence interval can be created using individual observations and predicitons. The hypothetical values can be replaced by relevant values. By default, a 90% confidence interval is given. To get, for instance, a 95% confidence interval, change alpha to 0.05.\n"
      ],
      "metadata": {
        "id": "u-xLvF5G-pUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observations = [132,\n",
        "                111,\n",
        "                120,\n",
        "                190,\n",
        "                115,\n",
        "                130,\n",
        "                ]\n",
        "\n",
        "predictions = [110,\n",
        "               121,\n",
        "               125,\n",
        "               170,\n",
        "               125,\n",
        "               130,\n",
        "               ]\n",
        "\n",
        "try:\n",
        "  CI_I_LD(observations, predictions, alpha=0.1)\n",
        "except NameError:\n",
        "  print('Run the first code block first to load the necessary functions.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGbGUp6w-sEq",
        "outputId": "cff0e7a0-616b-4740-cb3d-fb0a49d32e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GM-ratio: 0.9862482242209722\n",
            "90.0% confidence interval: [0.9080389449267313, 1.0711936588331088]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# G-LD appraoch"
      ],
      "metadata": {
        "id": "kktp5Xtn7pNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, only the geometric mean and coefficient of variation are published and not the individual AUC values. In this case, the first approach is not possible and the second approach must be used."
      ],
      "metadata": {
        "id": "SakMDp7n8WMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GM_observed = 120\n",
        "GM_predicted = 120\n",
        "GCV_observed = 0.4 # N.B. 40% should be entered as 0.4!\n",
        "GCV_predicted = 0.8\n",
        "N_observed = 20\n",
        "N_predicted = 200\n",
        "\n",
        "\n",
        "try:\n",
        "    CI_G_LD(GM_observed=GM_observed, GM_predicted=GM_predicted,\n",
        "            GCV_observed=GCV_observed, GCV_predicted=GCV_predicted,\n",
        "            N_observed=N_observed, N_predicted=N_predicted,\n",
        "            alpha=0.1)\n",
        "except NameError:\n",
        "    print('Run the first code block first to load the necessary functions.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Bh28oFUBbc6",
        "outputId": "4a2ae322-9811-4c44-e190-d144c62cff00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GM-ratio: 1.0\n",
            "90.0% confidence interval: [0.8451176483617664, 1.183267207753226]\n"
          ]
        }
      ]
    }
  ]
}